### Формула Пуассона
$$\lim_{\substack{n \to \infty \\ np = \alpha}} P_n(m) = \underbrace{e^{-\alpha}\frac{R^m}{m!}}_{R_{\infty}(m)}\text{\quad→\quad} 
\begin{align}
& \quad\quad\quad~~\text{распределение Пуассона:} \\
& r:
\left\{
\begin{array}{l}
  m: \quad~~~ 0 \quad\quad\quad 1 \quad\quad~ \ldots \quad~~~ k \\
  p: \quad~ p_{\infty}(0) \quad p_{\infty}(1) \quad \ldots \quad p_{\infty}(k)
\end{array}
\right.
\end{align}
$$
Проверим нормировку
$$\sum_{m=0}^{\infty} P_{\infty}(m)=\sum_{m=0}^{\infty}\frac{\alpha^m}{m!}e^{-\alpha}=e^{-\alpha}\underbrace{\sum_{m=0}^{\infty}\frac{\alpha^m}{m!}}_{\substack{\text{разл.в ряд} \\ \text{для exp(x)} \\ \text{около т. x=0}}}=e^{-\alpha}e^{\alpha}=1$$
Подписанное разложение в ряд около точки $x=0$ вот:
$$e^x = \sum_{m=0}^{\infty}\frac{x^m}{m!}$$
Производящая функция моментов:
$$g_r(\nu)=M[e^{\nu r}]=\sum_{m=0}^{\infty}e^{\nu m}P_{\infty}(m)=\sum_{m=0}^{\infty}\underbrace{e^{\nu m}}_{(e^{\nu})^m}e^{-\alpha}\frac{\alpha^m}{m!}=e^{-\alpha}\sum_{m=0}^{\infty}\frac{(\alpha e^{\nu})^m}{m!}=e^{-\alpha}e^{\alpha e^{\nu}}=\boxed{e^{-\alpha(1-e^{\nu})}}$$
`Задание`:
Вывести производящую функцию моментов (ПФМ) для распределения Пуассона через ПФМ биномиального распределения.
Найдём $M[r], D[r]$ (моменты и дисперсию):
$$M[r] = \frac{dg_r(0)}{d\nu}\Rightarrow \frac{dg_r(\nu)}{d\nu} = e^{-\alpha(1-\nu)}$$
$$\frac{dg_r(0)}{d\nu} = e^{-\alpha(1-e^0)}=\alpha\Rightarrow M[r]=\alpha$$
Сравниваем с иномиальным распределением: $M[r]=np$
$$M_2[r]=\frac{d^2g_r(0)}{d\nu^2}\Rightarrow \frac{d^2g_r(\nu)}{d\nu^2} = e^{-\alpha(1-e^{\nu})}\cdot (\alpha e^{\nu})^2+e^{-\alpha(1-e^{\nu})}\cdot\alpha e^{\nu}$$
$$\frac{d^2g_r(0)}{d\nu^2} = \alpha^2+\alpha\Rightarrow D[r]=M_2[r]-M^2[r]=\alpha^2+\alpha-\alpha^2=\alpha$$
Получаем, что и $M_{\nu}=\alpha$, и $D_{\nu}=\alpha$.
Сравним с биномиальным распределением:
$$D[r] = np(1-p) \xrightarrow[\scriptsize\substack{n\to\infty \\ np = \alpha}]{} \alpha$$
$$\lim_{\substack{n\to\infty \\ np=\alpha}}np(1-p)=\lim_{n\to\infty}\alpha\left(1-\frac{\alpha}{n}\right)=\alpha$$
### Локальная теорема Муавра–Лапласа
$$P_n(m)=C_n^m p^m(1-p)^{n-m}$$
$$\lim_{\substack{n\to\infty \\ p=const}}P_n(m)=?$$
Для больших $n~(n >> 1)$ и $p\approx const$, имеем приближение:
$$P_n(m)\underset{n\to\infty}\sim\frac{1}{\sqrt{2\pi np(1-p)}}\exp\left(-\frac{(m-np)^2}{2np(1-p)}\right)$$
Или оно же, раскрывая экспоненту:
$$\boxed{P_n(m)\underset{n\to\infty}\sim\frac{1}{\sqrt{2\pi np(1-p)}}e^{-\frac{(m-np)^2}{2np(1-p)}}}$$
`Как это запомнить`:
Это нормальный закон, у которого
$$M[r]=np,\quad D[r]=np(1-p)$$
(т.е. как у биномиального распределения).
Эквивалентность:
$$a_n\underset{n\to\infty}\sim b_n \Leftrightarrow \lim_{n\to\infty}\frac{a_n}{b_n}=1$$
то есть, вместо $a_n$ считаем $b_n$ по этой формуле нет никаких числительных неустойчивостей.
`Пример`:
$$n=10^3,\ p=0.5,\ m=100$$
$$P_{1000}(100)\approx \frac{1}{\sqrt{2\pi\cdot10^3\cdot0.5\cdot0.5}}\cdot e^{-\frac{(100-500)^2}{2\cdot10^3\cdot0.5\cdot0.5}}\approx\frac{1}{50}e^{\frac{-16\cdot 10^4}{0.5\cdot10^3}}\approx\frac{1}{50}e^{-320} \approx 2\cdot10^{-162}$$
Д.С.В. (двумерные случайные векторы)
$$\vec{r}=\begin{pmatrix}r_1 \\ r_2\end{pmatrix},~где~r_1 \text{ и } r_2 \text{ - ДСВ}$$
$$
r_1:
\left\{
\begin{array}{l}
  x: \quad~~~ x_1 \quad~ x_2 \quad \ldots \quad~ x_n \\
  p_1: \quad~ p_{11} \quad p_{12} \quad \ldots \quad p_{1n}
\end{array}
\right.
\quad\quad
r_2:
\left\{
\begin{array}{l}
  y: \quad~~~ y_1 \quad~~ y_2 \quad \ldots \quad~ y_m \\
  p_2: \quad~ p_{21} \quad p_{22} \quad \ldots \quad p_{2m}
\end{array}
\right.
$$
Этих распределений недостаточно, чтобы описать его значения — это комбинации, сочетания $(x_i, y_j)$
$$P((r_1=x_i)\cap(r_2=y_j))=P(r_1=x_i)\cdot P(r_2=y_j|r_1=x_i)=q_{ij}$$
Нужна ещё условная вероятность.
Полное описание $\vec{r}$:
$$
\begin{matrix}
\vec{r}:r_1|r_2& y_1 & y_2 & \dots & y_m \\
x_1 & q_{11} & q_{12} & \dots & q_{1m} \\
x_2 & q_{21} & q_{22} & \dots & q_{2m} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
x_n & q_{n1} & q_{n2} & \dots & q_{nm} 
\end{matrix}
$$
$\vec{r}$ — случайное блуждание по разграфленной плоскости:
![[02 - Areas/Education/Mathematics/Probability Theory & Statistics/Theory/img/004.png]]
Среднее в i-ой строке:
$$\sum_{j=1}^{m}q_{ij}=\sum_{j=1}^{m}P((r_2=y_j)\cdot P(r_1=x_i|r_2=y_j))=$$
т.к. все события вида $r_2=y_j$ образуют группу, то по формуле полной вероятности:
$$=P(r_1=x_i)=p_{1i}$$
Аналогично среднее в j-ом столбце
$$\sum_{i=1}^{n}q_{ij}=\overline{p_{2j}}$$
$$\sum_{i=1}^{n}\sum_{j=1}^{m}q_{ij}=\sum_{j=1}^{m}\sum_{i=1}^{n}q_{ij}=\sum_{i=1}^{n}\overline{p_{1j}}=\sum_{j=1}^{m}\overline{p_{2j}}=1~-~\text{совместное распред. (joint)}$$
распределения $r_1 \text{ и } r_2$ — маргинальные (marginal)
условные → безусловные
Признак независимости $r_1 \text{ и } r_2$:
$$\boxed{q_{ij}=p_{1i}\cdot p_{2j}}~\forall i,j \Leftrightarrow r_1 \text{ и } r_2~-~\text{независимы}$$
`Пример`
Дано совместное распределение. Как найти моменты?
• Начальные:
$$m_{k}[r_i]=\sum_{i=1}^{n}x_i^kp_{1i}=\boxed{\sum_{i=1}^{n}\sum_{j=1}^{m}x_i^k q_{ij}}$$
$$m_k[r_2]=\sum_{j=1}^{m}y_j^k p_{2j}=\boxed{\sum_{i=1}^{n}\sum_{j=1}^{m}y_j^k q_{ij}}$$
• Центральные:
$$m_k^0[r_1]=\sum_{i=1}^{n}(x_i-M[r_1])^kp_{1i}=\boxed{\sum_{i=1}^{n}\sum_{j=1}^{m}(x_i-M[r_1])^kq_{ij}}$$
$$m_k^0[r_2]=\sum_{i=1}^{n}(x_i-M[r_1])^kp_{1i}=\boxed{\sum_{i=1}^{n}\sum_{j=1}^{m}(y_j-M[r_2])^kq_{ij}}$$
Кстати, именно так и вычисляется средняя интенсивность пикселей.
`Пример`
$$m_{k}[r_1]=m_1[r_1]=\sum_{i=1}^{n}\sum_{j=1}^{m}x_i q_{ij}$$
$$m_{k}[r_2]=m_2^0[r_2]=\sum_{i=1}^{n}\sum_{j=1}^{m}(y_j-M[r_2])^2 q_{ij}$$
Взаимосвязи между $r_1 \text{ и } r_2$ описываются смешанными (mixed) начальными моментами:
$$M_{k,\alpha}^0[r_1, r_2]=\sum_{i=1}^{n}\sum_{j=1}^{m}x_i^k\cdot y_j^{\alpha}\cdot q_{ij}$$
Центральными смешанными моментами:
$$M_{k,\alpha}^0[r_1, r_2]=\sum_{i=1}^{n}\sum_{j=1}^{m}(x_i-M[r_i])^k \cdot (y_j-M[r_2])^{\alpha}\cdot q_{ij}$$
Особое значение имеет $M_{1,1}^0[r_1, r_2]$ — ковариация (covariance) — совместное изменение.